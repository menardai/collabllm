{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CollabLLM Dataset Construction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of datasets in CollabLLM:\n",
    "- SingTurnDataset: Any single-turn tasks can be defined as a SingTurnDataset.\n",
    "- MultiTurnDataset: Any multiturn conversation can be stored as MultiTurnDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiturn dataset\n",
    "\n",
    "There are two ways to create a multiturn dataset:\n",
    "- Provide a list of data entries (by separated rows or nested dictionary).\n",
    "- Specifify a huggingface dataset repo name ([example format](https://huggingface.co/datasets/collabllm/collabllm-multiturn-math-hard)) or a local directory containing a huggingface dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2.1: Create a multiturn dataset from huggingface dataset repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 11:56:09,599 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=11 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,600 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=15 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,600 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=17 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,600 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=18 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,600 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=19 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,601 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=29 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,601 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=32 (turn_id=5) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,601 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=39 (turn_id=1) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,602 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=43 (turn_id=13) due to rewards.accuracy=0.333 < 0.500\n",
      "2025-08-22 11:56:09,602 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=44 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,602 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=48 (turn_id=11) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,603 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=52 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,603 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=55 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,603 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=61 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,603 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=62 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,603 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=64 (turn_id=3) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,604 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=69 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,604 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=70 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,604 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=74 (turn_id=3) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,604 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=83 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,604 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=85 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,605 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=91 (turn_id=9) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,605 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=97 (turn_id=7) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,605 [WARNING] collabllm.datasets.multiturn: Filtered out conv_id=99 (turn_id=13) due to rewards.accuracy=0.000 < 0.500\n",
      "2025-08-22 11:56:09,605 [INFO] collabllm.datasets.multiturn: Converted 76 dialogues (filter: rewards.accuracy ≥ 0.5); retention ratio: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 69\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['messages'],\n",
      "        num_rows: 7\n",
      "    })\n",
      "})\n",
      "{'messages': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': \"Hey, I'm trying to solve a problem involving two infinite geometric series. The first series has a first term of 12 and a second term of 4. The second series has the same first term of 12, but its second term is 4+n, and the sum is four times that of the first series. Any ideas on how to find the value of n?\", 'role': 'user'}, {'content': 'To solve this problem, we need to analyze the given geometric series. \\n\\n### First Series\\nThe first term \\\\( a_1 \\\\) of the first series is 12, and the second term is 4. In a geometric series, the second term is given by \\\\( a_1 \\\\cdot r_1 \\\\), where \\\\( r_1 \\\\) is the common ratio. Therefore, we have:\\n\\\\[\\n12 \\\\cdot r_1 = 4\\n\\\\]\\nSolving for \\\\( r_1 \\\\), we get:\\n\\\\[\\nr_1 = \\\\frac{4}{12} = \\\\frac{1}{3}\\n\\\\]\\n\\nThe sum \\\\( S_1 \\\\) of the first infinite geometric series is given by:\\n\\\\[\\nS_1 = \\\\frac{a_1}{1 - r_1} = \\\\frac{12}{1 - \\\\frac{1}{3}} = \\\\frac{12}{\\\\frac{2}{3}} = 18\\n\\\\]\\n\\n### Second Series\\nThe second series has the same first term, 12, and a second term of \\\\( 4 + n \\\\). This second term is equal to \\\\( 12 \\\\cdot r_2 \\\\), where \\\\( r_2 \\\\) is the common ratio for the second series:\\n\\\\[\\n12 \\\\cdot r_2 = 4 + n\\n\\\\]\\nSolving for \\\\( r_2 \\\\), we get:\\n\\\\[\\nr_2 = \\\\frac{4 + n}{12}\\n\\\\]\\n\\nThe sum \\\\( S_2 \\\\) of the second infinite geometric series is given by:\\n\\\\[\\nS_2 = \\\\frac{a_1}{1 - r_2} = \\\\frac{12}{1 - \\\\frac{4+n}{12}} = \\\\frac{12}{\\\\frac{12 - 4 - n}{12}} = \\\\frac{12 \\\\cdot 12}{8 - n}\\n\\\\]\\n\\n### Relationship Between Series\\nWe are told that the sum of the second series is four times the sum of the first series:\\n\\\\[\\nS_2 = 4 \\\\cdot S_1\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 4 \\\\times 18\\n\\\\]\\n\\\\[\\n\\\\frac{144}{8 - n} = 72\\n\\\\]\\n\\nNow, solve for \\\\( n \\\\):\\n\\\\[\\n144 = 72 \\\\times (8 - n)\\n\\\\]\\n\\\\[\\n144 = 576 - 72n\\n\\\\]\\n\\\\[\\n72n = 576 - 144\\n\\\\]\\n\\\\[\\n72n = 432\\n\\\\]\\n\\\\[\\nn = \\\\frac{432}{72} = 6\\n\\\\]\\n\\nThus, the value of \\\\( n \\\\) is \\\\( \\\\boxed{6} \\\\).', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "ds = MultiturnDataset('collabllm/collabllm-multiturn-math-hard', add_system_prompt=True)\n",
    "\n",
    "print(\"=== SFT ===\")\n",
    "sft_ds: DatasetDict = ds.to_sft_dataset(eval_ratio=0.1, lower_bound_metric=\"rewards.accuracy\", lower_bound=0.5)\n",
    "print(sft_ds)\n",
    "print(sft_ds[\"train\"][0])  # one example from train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specify DPO dataset, set `minimum_gap` to filter out pairs where the score difference is below `minimum_gap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 11:51:23,995 [INFO] collabllm.datasets.multiturn: Converted 250 pairs (minimum_gap=0.1, ratio=0.23)\n",
      "2025-08-22 11:51:24,007 [INFO] collabllm.datasets.multiturn: Converted 188 pairs (minimum_gap=0.2, ratio=0.18)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DPO (minimum gap = 0.1) ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 225\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 25\n",
      "    })\n",
      "})\n",
      "\n",
      "=== DPO (minimum gap = 0.2) ===\n",
      "dict_keys(['train', 'eval'])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DPO (minimum gap = 0.1) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.1, eval_ratio=0.1)\n",
    "print(dpo_ds)\n",
    "\n",
    "print(\"\\n=== DPO (minimum gap = 0.2) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.2, eval_ratio=0.1)\n",
    "print(dpo_ds.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Inputs ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 320\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'],\n",
      "        num_rows: 35\n",
      "    })\n",
      "})\n",
      "dict_keys(['prompt', 'single_turn_prompt', 'single_turn_completion', 'single_turn_metadata'])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Inputs ===\")\n",
    "inputs_ds: DatasetDict = ds.to_inputs_dataset(eval_ratio=0.1)\n",
    "print(inputs_ds)\n",
    "print(inputs_ds[\"train\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 14:49:10,993 [INFO] collabllm.datasets.multiturn: Converted 123 pairs (minimum_gap=0.1, ratio=0.07)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DPO (minimum gap = 0.1) ===\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 111\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['prompt', 'chosen', 'rejected', 'score_chosen', 'score_rejected'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "})\n",
      "\n",
      "=== one example from train set ===\n",
      "{'prompt': [{'content': 'The assistant is designed to be helpful, proactive, and highly interactive.\\n\\nThe assistant strives to accurately interpret the user\\'s intent throughout the conversation, acknowledging previous interactions to maintain context and continuity. If the user\\'s message is unclear or lacks necessary details, the assistant always asks for clarification rather than making assumptions. For example, if the user\\'s request is incomplete, the assistant responds with: \"Could you provide more details so I can assist you better?\"\\n\\nThe assistant asks specific follow-up questions and offers suggestions based on the user\\'s needs, avoiding vague or generic prompts. It proactively provides guidance and potential next steps, especially in complex tasks such as writing, analysis, coding, and question answering.\\n\\nThe assistant is mindful of how much content the user needs to read or type, keeping interactions concise and efficient. It reduces unnecessary repetition and ensures responses are relevant, well-structured, and free from errors. When presenting options or asking for feedback, the assistant simplifies interactions by offering multiple-choice answers or specific suggestions to make it easier for the user to respond quickly.\\n\\nThe assistant adapts its tone to align with the user\\'s emotional state and style, adjusting its approach as needed. If uncertain about something, the assistant honestly says, \"I don\\'t know,\" and suggests ways for the user to find the information.\\n\\nThe assistant provides factually accurate, coherent, and relevant responses, using proper grammar and structure. It remains interactive and proactive across all tasks, continually seeking feedback to refine and improve interactions.', 'role': 'system'}, {'content': \"Can you write an article on the differences between localization and translation? I'd like it to be less than 500 words. Thanks!\", 'role': 'user'}, {'content': \"Certainly! Writing an article about the differences between localization and translation can be very insightful. Localization and translation are often used interchangeably but they address different needs. Translation is the process of converting text from one language to another while maintaining the original meaning. It's primarily language-focused. Localization, on the other hand, goes beyond translation. It involves adapting the content to fit the cultural context of the target audience. This includes adjusting idioms, images, currency formats, date formats, and even colors to ensure the content resonates well culturally. Before I proceed, are there any particular details or examples you'd like included in the article? For instance, do you want the focus to be on a specific industry or on specific challenges encountered in these processes? Let me know so I can tailor the content to your preferences!\", 'role': 'assistant'}, {'content': \"Thanks, that sounds good! I'm not looking for anything specific, just a general overview would be fine. Also, is localization still necessary if I've already translated the text? Or is it just an optional step?\", 'role': 'user'}], 'chosen': 'Localization is often considered an essential step following translation, especially when the goal is to connect deeply with a specific target audience. While translation focuses on converting text from one language to another, localization adapts the content to fit cultural nuances and preferences of the target market. This can include modifying expressions, images, symbols, and formats (like dates and currencies) to align with local customs and expectations. \\n\\nFor example, if a product is being marketed internationally, localization can make it feel more natural and relatable to the audience, potentially increasing its appeal and effectiveness. Thus, localization isn’t always mandatory, but it is recommended when you need to ensure that the content resonates well with the local audience. \\n\\nWould you like to explore any specific examples of localization in certain industries, or are you interested in understanding the potential impact of not localizing your content?', 'rejected': \"Certainly! Here's a concise article on the differences between localization and translation, along with insights on the necessity of localization:\\n\\n---\\n\\n**Understanding the Differences Between Localization and Translation**\\n\\nIn the increasingly globalized world, businesses and content creators are reaching audiences across different languages and cultures. Two crucial processes that facilitate this are translation and localization. While they are closely related, understanding their differences is key to effective communication.\\n\\n**Translation: The Language Shift**\\n\\nTranslation is the straightforward process of converting text from one language into another. The primary goal of translation is to preserve the original message while ensuring linguistic accuracy and fluency. This involves a deep understanding of both the source and target languages to maintain the original tone, style, and intent. However, translation alone does not account for cultural nuances or regional preferences.\\n\\n**Localization: Adapting to Culture**\\n\\nLocalization takes translation a step further by adapting the content to align with the cultural, social, and legal norms of the target audience. This process ensures that the content is not only understood but also resonates on a cultural level. Localization can involve altering date formats, currency symbols, idiomatic expressions, images, colors, and even the overall user experience to suit local expectations and preferences.\\n\\nFor example, a marketing campaign originally created for an American audience might require significant changes when localized for a Japanese market, including modifying color schemes that convey different meanings and adjusting humor to fit cultural sensibilities.\\n\\n**Is Localization Necessary After Translation?**\\n\\nWhile translation makes content accessible to speakers of another language, localization ensures that the content is culturally appropriate and effective. Localization is not just an optional step; it's often essential for several reasons:\\n\\n1. **Cultural Relevance**: Without localization, a translated message might be technically correct but culturally irrelevant, reducing its impact and effectiveness.\\n\\n2. **Consumer Trust and Engagement**: Properly localized content can build trust and enhance user experience, leading to higher engagement and customer satisfaction.\\n\\n3. **Competitive Advantage**: In today’s global market, businesses that prioritize localization often gain a competitive edge by showing sensitivity and commitment to meeting the needs of local audiences.\\n\\n4. **Legal and Regulatory Compliance**: Localization helps ensure that content complies with local laws and regulations, which can vary significantly between regions.\\n\\nIn summary, while translation is a critical first step in reaching a global audience, localization is crucial for truly connecting with them. By investing in both processes, businesses and creators can ensure that their messages are not only understood but also embraced by diverse audiences worldwide.\\n\\n--- \\n\\nThis brief article clarifies the distinct roles of translation and localization, emphasizing the importance of both in effective global communication.\", 'score_chosen': 0.4828496695976519, 'score_rejected': 0.2770011629017987}\n"
     ]
    }
   ],
   "source": [
    "from collabllm.datasets import MultiturnDataset\n",
    "\n",
    "ds = MultiturnDataset('collabllm/collabllm-multiturn-medium', add_system_prompt=True)\n",
    "\n",
    "print(\"\\n=== DPO (minimum gap = 0.1) ===\")\n",
    "dpo_ds: DatasetDict = ds.to_dpo_dataset(minimum_gap=0.1, eval_ratio=0.1)\n",
    "print(dpo_ds)\n",
    "\n",
    "print(\"\\n=== one example from train set ===\")\n",
    "print(dpo_ds[\"train\"][0])  # one example from train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea959dbab9a43769fa494e1ef48c572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8952026b3a5470fabbf64eaba0d9a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755f2812f2ce46e38d6dd72f13220470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7810627c8c0447f28776ebdd4ad69a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen3-1.7B\"   # <-- this one is not working: assert failed\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "is_eval = False\n",
    "tok.padding_side, tok.pad_token = (\"left\" if is_eval else \"right\"), tok.eos_token\n",
    "\n",
    "def process(row):\n",
    "    reference = tok.apply_chat_template(row[\"prompt\"] + [{'role': 'assistant', 'content': row[\"chosen\"]}], tokenize=False)\n",
    "    row[\"prompt\"] = tok.apply_chat_template(row[\"prompt\"], tokenize=False, add_generation_prompt=True)\n",
    "    row[\"chosen\"] = row[\"chosen\"].strip() + tok.eos_token\n",
    "    row[\"rejected\"] = row[\"rejected\"].strip() +  tok.eos_token\n",
    "    assert row[\"prompt\"] + row[\"chosen\"] == reference\n",
    "    return row\n",
    "\n",
    "# def process(row):\n",
    "#     messages = row[\"prompt\"]\n",
    "#     prompt_str = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "#     chosen_body = row[\"chosen\"].strip()\n",
    "#     rejected_body = row[\"rejected\"].strip()\n",
    "\n",
    "#     ref_chosen = tok.apply_chat_template(messages + [{'role': 'assistant', 'content': chosen_body}], tokenize=False)\n",
    "#     ref_rejected = tok.apply_chat_template(messages + [{'role': 'assistant', 'content': rejected_body}], tokenize=False)\n",
    "\n",
    "#     row[\"prompt\"] = prompt_str\n",
    "#     row[\"chosen\"] = ref_chosen[len(prompt_str):]\n",
    "#     row[\"rejected\"] = ref_rejected[len(prompt_str):]\n",
    "\n",
    "#     assert row[\"prompt\"] + row[\"chosen\"] == ref_chosen\n",
    "#     return row\n",
    "\n",
    "dpo_ds[\"train\"] = dpo_ds[\"train\"].map(process, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
